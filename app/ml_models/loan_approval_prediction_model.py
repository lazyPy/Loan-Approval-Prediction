# -*- coding: utf-8 -*-
"""loan_approval_prediction_model (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GU994DL8m8SWMcEILsumuYdH6619uxwr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer
import os
import warnings
import joblib
warnings.filterwarnings('ignore')

# Set the style for plots
plt.style.use('ggplot')
sns.set(font_scale=1.2)
sns.set_style("whitegrid")

# Load the dataset
print("Loading dataset...")
data_path = "DataForTestingLoanApproval.csv"
df = pd.read_csv(data_path)

# Display basic information about the dataset
print("\nDataset Overview:")
print(f"Shape: {df.shape}")
print("\nFirst few rows:")
print(df.head())

# Check for missing values
print("\nMissing values in each column:")
print(df.isnull().sum())

# Data preprocessing
print("\nPerforming data preprocessing...")

# Convert 'Loan Status' to binary (1 for Approved, 0 for Declined)
df['Loan Status'] = df['Loan Status'].apply(lambda x: 1 if x == 'Approved' else 0)

# Check class distribution
print("\nClass distribution:")
print(df['Loan Status'].value_counts())
print(f"Percentage of approved loans: {df['Loan Status'].mean() * 100:.2f}%")

# Check for class imbalance
approved_count = df['Loan Status'].sum()
declined_count = len(df) - approved_count
imbalance_ratio = approved_count / declined_count
print(f"\nImbalance ratio (Approved/Declined): {imbalance_ratio:.2f}")

# Calculate class weights
# The weight for each class is inversely proportional to class frequency
total_samples = len(df)
n_classes = 2
class_weights = {
    0: total_samples / (n_classes * declined_count),  # Weight for declined loans
    1: total_samples / (n_classes * approved_count)   # Weight for approved loans
}
print(f"\nClass weights to address imbalance:")
print(f"Declined (0): {class_weights[0]:.4f}")
print(f"Approved (1): {class_weights[1]:.4f}")

# Identify categorical and numerical columns
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
numerical_cols.remove('Loan Status')  # Remove target variable from numerical columns

print(f"\nCategorical columns: {categorical_cols}")
print(f"Numerical columns: {numerical_cols}")

# Create feature matrix X and target vector y
X = df.drop('Loan Status', axis=1)
y = df['Loan Status']

# Define preprocessing for numerical and categorical features
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Combine preprocessing steps
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Split the data into training and testing sets (80/20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print(f"\nTraining set size: {X_train.shape[0]}")
print(f"Testing set size: {X_test.shape[0]}")

# Create a pipeline with preprocessing and model
# Use class_weight parameter to address class imbalance
dt_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', DecisionTreeClassifier(random_state=42, class_weight=class_weights))
])

# Define hyperparameters for grid search
param_grid = {
    'classifier__max_depth': [3, 5, 7, 10, None],
    'classifier__min_samples_split': [2, 5, 10],
    'classifier__min_samples_leaf': [1, 2, 4],
    'classifier__criterion': ['gini', 'entropy']
}

# Perform grid search with cross-validation
print("\nPerforming grid search with cross-validation...")
grid_search = GridSearchCV(
    dt_pipeline,
    param_grid,
    cv=5,
    scoring='f1',  # Optimize for F1 score (balance of precision and recall)
    n_jobs=-1
)

# Train the model
grid_search.fit(X_train, y_train)

# Get the best model
best_model = grid_search.best_estimator_
print(f"\nBest parameters: {grid_search.best_params_}")

# Evaluate the model on the test set
y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)[:, 1]

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)

print("\nModel Evaluation Metrics:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"ROC AUC: {roc_auc:.4f}")

# Display confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Declined', 'Approved'],
            yticklabels=['Declined', 'Approved'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.close()

print("\nDetailed Classification Report:")
print(classification_report(y_test, y_pred, target_names=['Declined', 'Approved']))

# Cross-validation scores
cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='f1')
print(f"\n5-Fold Cross-Validation F1 Scores: {cv_scores}")
print(f"Mean F1 Score: {cv_scores.mean():.4f}")
print(f"Standard Deviation: {cv_scores.std():.4f}")

# Extract the trained decision tree
dt_classifier = best_model.named_steps['classifier']

# Get feature names after preprocessing
preprocessor = best_model.named_steps['preprocessor']
cat_features = preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(categorical_cols)
feature_names = numerical_cols + list(cat_features)

# Feature importance
feature_importance = dt_classifier.feature_importances_

# Create a DataFrame for feature importance
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importance
})

# Sort by importance
importance_df = importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)

# Display top 3 important features
print("\nTop 3 Important Features:")
print(importance_df.head(3))

# Plot feature importance
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df.head(3))
plt.title('Top 3 Feature Importance')
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
plt.close()

# Visualize the decision tree (top 3 levels)
plt.figure(figsize=(20, 10))
plot_tree(dt_classifier,
          feature_names=feature_names,
          class_names=['Declined', 'Approved'],
          filled=True,
          rounded=True,
          max_depth=3)
plt.title('Decision Tree (Top 3 Levels)')
plt.savefig('decision_tree.png', dpi=300, bbox_inches='tight')
plt.close()

# Save the trained model to a file (this is the only essential file)
model_path = 'loan_approval_model.joblib'
joblib.dump(best_model, model_path)
print(f"\nTrained model saved to '{model_path}'")